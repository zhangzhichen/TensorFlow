1.保证千亿级数据。
多个生产者:对应多个partition
多个消费者:固定的分区限制，比如三个生产者，三个消费者（一人一个分区）。两个消费者（其中一个两个分区。）

分区数发生变化，或者新加入或减少消费者->rebalance操作

range分区:
n=分区数量/消费者数量
m=分区数量%消费者数量

roundRobin:
按照hashCode轮询
例:5,3,0,8,2,1,4,7,6,9
C1:5,8,4,9
c2:2,2,7
c3:0,1,6

stricky
1.尽可能均匀。
2.尽可能与上一次分配保持一致。
C1,C2,C3


coordinator选举出consumerLeader
消费者的分区策略，由consumerLeader进行。

消费的依据:gpid->test partition->offset三个要素决定
offset之前的版本维护在zk上，但是由于watcher机制，客户端很多的时候，需要都通知到，产生性能问题。
后来存储在磁盘上。

行为跟踪：kafka可以用于跟踪用户浏览页面、搜索及其他行为。通过发布-订阅模式实时记录到对应的
topic中，通过后端大数据平台接入处理分析，并做更进一步的实时处理和监控

日志收集：日志收集方面，有很多比较优秀的产品，比如Apache Flume，很多公司使用kafka代理日志
聚合。日志聚合表示从服务器上收集日志文件，然后放到一个集中的平台（文件服务器）进行处理。在
实际应用开发中，我们应用程序的log都会输出到本地的磁盘上，排查问题的话通过linux命令来搞定，
如果应用程序组成了负载均衡集群，并且集群的机器有几十台以上，那么想通过日志快速定位到问题，
就是很麻烦的事情了。所以一般都会做一个日志统一收集平台管理log日志用来快速查询重要应用的问
题。所以很多公司的套路都是把应用日志集中到kafka上，然后分别导入到es和hdfs上，用来做实时检
索分析和离线统计数据备份等。而另一方面，kafka本身又提供了很好的api来集成日志并且做日志收集


副本(备用分区):
1.每个topic只有leader进行数据处理。
2.每个副本只做数据备份，同步。
ISR维护的是和leader副本数据差不多的数据的副本集合（如果副本同步时间超过最大配置时间，说明数据不同步，把它踢掉）
因为同步它的时候会浪费很多时间，因此采用异步同步的方式。


kafka同步方式:
1.follower发送一个sync请求给leader.

kafka选举方式:
并不需要保持数据一致性问题，不需要很复杂。



LEO(log end offset)  当前副本的最大offset
HW(higer watcher)    所有副本中，最大公用offset







